# -*- coding: utf-8 -*-
"""Unit4-BuildWeekProject-AirBnB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BPumSgU0gIerQSki65sQGoZdI9ZJpiPI
"""

import pandas as pd
import numpy as np

from google.colab import files
files.upload()

listing_df = pd.read_csv("listings.csv.gz")

listing_df.to_csv('listings.csv')

listing_df.head()

listing_df['neighbourhood_cleansed'].nunique()

listing_df['property_type'].nunique()

"""Columns:

**name**: Has no nulls, but has high cardinality categorical variables. (turning this into the index.)


**host_is_superhost**: 0 nulls. 2 unique values(boolean). 

**host_listings_count**: Has 0 nulls. (Keeping this column, because it appears to affect price). Has 42 unique values.


**neighbourhood_cleansed**: This has 0 nulls and 78 unique values. 


**property_type**: 0 nans. 40 unique values. 

**accommodates**: 0 nans. 17 unique values. Contains how many people they will accommodate for.


**bathrooms_text**: 5 nulls. dropping nulls.

**bedrooms**: 244 nulls. dropping nulls because we need number of bedrooms and 
would affect the price if we changed all of these.

**price**: 0 nulls. Check unique values

**minumum_nights**: 0 nulls, 39 unique values.

**maximum_nights**: 0 nulls, 100 unique values.


**has_availability**: 0 nulls. 2 unique values (boolean). 


**instant_bookable**: 0 nulls. 2 unique values (boolean). 




"""

#Plotly Express scatter plot of Category vs Price
##Showing the outliers
import plotly.express as px
fig = px.scatter(listing_df, x='property_type', y='price', title='Price per Property Type')


fig.show()

#columns_to_keep1 = ['host_is_superhost', 'host_listings_count',
                         #'neighbourhood_cleansed', 'property_type',
                         #'accommodates', 'bathrooms_text', 'bedrooms',
                         #'price', 'maximum_nights', 'minimum_nights',
                         #'has_availability', 'instant_bookable']

#df = listing_df[columns_to_keep1]

#df.head()

"""## I. Wrangle Data

# New Section
"""

def wrangle(X):
  # make a copy of the dataframe
  X = X.copy()

  columns_to_keep = ['host_is_superhost', 'host_listings_count',
                     'neighbourhood_cleansed', 'property_type',
                     'accommodates', 'bathrooms_text', 'bedrooms',
                     'maximum_nights', 'minimum_nights', 'price',
                     'has_availability', 'instant_bookable']

  X = X[columns_to_keep]

  # remove the rows with missing host values
  X.dropna(subset=['host_listings_count'], inplace=True)

  # remove the rows with missing number of bathrooms
  X.dropna(subset=['bathrooms_text'], inplace=True)

  # drop na's in bedrooms column and turned floats into ints
  X.dropna(subset=['bedrooms'], inplace=True)
  X['bedrooms'] = X['bedrooms'].astype(int)

  #clean the 'price' column: remove '$' and ',' 
  #change type to float.
  price = X['price'].str.replace('$', '').str.replace(',', '').astype(float)
  X['price'] = price


  # get rid of outliers in target
  #Remove 'Price' outliers > 3000.00
  outliers = X['price'] > 3000.00
  X=X[~outliers]


  return X

#Wrangle df
df = wrangle(listing_df)

print(df.shape)
df.head()



from keras.callbacks import ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error 
from matplotlib import pyplot as plt
import seaborn as sb
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import warnings 
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=DeprecationWarning)
from xgboost import XGBRegressor

df.replace('t',1, inplace=True)
df.replace('f',0, inplace=True)
df.head()

df.isnull().any()

df['bathrooms_text'].value_counts()

df.isin([""]).any()

import re
df['bathrooms_text'] = df['bathrooms_text'].apply(lambda x:re.sub('[^.0-9]', '', x))

df['bathrooms_text'].value_counts()

df = df[df['bathrooms_text'] != '']

df[['host_is_superhost', 'bathrooms_text', 'has_availability', 'instant_bookable']].astype(float)

df.head

pip install category_encoders

# Instantiate transformer - one hot encoder
from category_encoders import OneHotEncoder
transformer = OneHotEncoder(use_cat_names=True)

# Transform to fit training data
transformer.fit(df)

# Transform our training data
df = transformer.transform(df)

X = df.drop('price', axis=1)
y= df['price']

X = X.astype(float)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from keras.layers import BatchNormalization, Dropout
import keras

model = Sequential([

# The Input Layer :
Dense(1024, input_dim = X_train.shape[1]),
BatchNormalization(),
Dropout(0.4),


# The Hidden Layers :
#HL1
Dense(256, kernel_initializer='normal'),
BatchNormalization(),
Dropout(0.2),


#HL 2
Dense(256, kernel_initializer='normal'),
BatchNormalization(),
Dropout(0.1),

#HL 3
Dense(256, kernel_initializer='normal'),
BatchNormalization(),
Dropout(0.05),


# The Output Layer :
Dense(1, kernel_initializer='normal')
])

# Compile the network :
model.compile(loss='mean_absolute_error', optimizer = keras.optimizers.Adam(lr=0.01, decay=5e-5), metrics=['mean_absolute_error'])
model.summary

checkpoint_name = 'Weights\Weights-{epoch:03d}--{val_mean_absolute_error:.5f}.hdf5' 
checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_mean_absolute_error', verbose = 1, save_best_only = True, mode ='auto')
callbacks_list = [checkpoint]

model.fit(X_train, y_train, epochs=300, batch_size=1024, validation_data=(X_test,y_test), callbacks=callbacks_list)

!mkdir -p saved_model
model.save('saved_model/my_model')